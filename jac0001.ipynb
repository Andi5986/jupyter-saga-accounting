{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"background-color: #3933FF; border: 0px; -moz-border-radius: 10px; -webkit-border-radius: 10px;\">\n",
    "<h2 style=\"color: white\">\n",
    "Importing & Cleansing Data\n",
    "</h2><br>\n",
    "</div>\n",
    "\n",
    "> ### The Excel file contains a journal entry and is generated by SAGA Accounting. \n",
    "> ### Perform some data cleansing to make it user friendly. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = '/Users/andi/Desktop/CPD/REGISTRU JURNAL 29112023 1651.xls'\n",
    "df = pd.read_excel(file_path)\n",
    "df.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(file_path, header=8)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['crt.'], inplace=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[df['Explicatie'].str.contains('google', case=False) & (df['debitor'] == 628)]\n",
    "sum_debitor = filtered_df['debitor'].sum()\n",
    "filtered_df, sum_debitor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[\n",
    "    df['Explicatie'].str.contains('Google', case=False) \n",
    "    & (df['creditor'] != 512.1)\n",
    "    ]\n",
    "sum_debit = filtered_df['Debit'].sum()\n",
    "sum_debit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"background-color: #3933FF; border: 0px; -moz-border-radius: 10px; -webkit-border-radius: 10px;\">\n",
    "<h2 style=\"color: white\">\n",
    "More Power\n",
    "</h2><br>\n",
    "</div>\n",
    "\n",
    "> ### We connect extrenal libraries\n",
    "> ### We bring the currency to the journal entry "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from forex_python.converter import CurrencyRates\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def get_historical_rates(currency_from, currency_to, start_year, end_year):\n",
    "    c = CurrencyRates()\n",
    "    \n",
    "    start_date = datetime(start_year, 1, 1)\n",
    "    end_date = datetime(end_year, 12, 31)\n",
    "\n",
    "    rates = {}\n",
    "    current_date = start_date\n",
    "    while current_date <= end_date:\n",
    "        try:\n",
    "            rate = c.get_rate(currency_from, currency_to, current_date)\n",
    "            rates[current_date.strftime('%Y-%m-%d')] = rate\n",
    "        except Exception as e:\n",
    "            print(f\"Could not fetch rate for date: {current_date.strftime('%Y-%m-%d')}. Error: {e}\")\n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "    return rates\n",
    "\n",
    "historical_rates = get_historical_rates('EUR', 'RON', 2023, 2023)\n",
    "print(historical_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['Exchange Rate'] = df['Data'].apply(lambda x: historical_rates.get(x.strftime('%Y-%m-%d'), None) if pd.notnull(x) else None)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[\n",
    "    df['Explicatie'].str.contains('Google', case=False) \n",
    "    & (df['creditor'] != 512.1)\n",
    "    ]\n",
    "filtered_df['Debit_with_exchange'] = filtered_df['Debit'] / filtered_df['Exchange Rate']\n",
    "sum_debit = filtered_df['Debit_with_exchange'].sum()\n",
    "sum_debit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Debitor_First_3'] = df['debitor'].astype(str).str.slice(stop=3)\n",
    "df['Creditor_First_3'] = df['creditor'].astype(str).str.slice(stop=3)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[df['Debitor_First_3'] == '628']\n",
    "filtered_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_descriptions = filtered_df.groupby('Explicatie')['Debit'].sum().reset_index().rename(columns={'Debit': 'Total Debit Amount'})\n",
    "\n",
    "unique_descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"background-color: #3933FF; border: 0px; -moz-border-radius: 10px; -webkit-border-radius: 10px;\">\n",
    "<h2 style=\"color: white\">\n",
    "Plotting and Presentation\n",
    "</h2><br>\n",
    "</div>\n",
    "\n",
    "> ### We can plot as in excel spreadsheets\n",
    "> ### Here we are plotting the daily cash at bank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bank_df = df[df['debitor'].astype(str).str.startswith('512') | df['creditor'].astype(str).str.startswith('512')]\n",
    "\n",
    "bank_df['Amount'] = bank_df.apply(lambda row: row['Debit'] if str(row['debitor']).startswith('512') else -row['Credit'], axis=1)\n",
    "\n",
    "bank_df['Balance'] = bank_df['Amount'].cumsum()\n",
    "\n",
    "plt.plot(bank_df['Balance'])\n",
    "plt.xlabel('Transaction')\n",
    "plt.ylabel('Balance')\n",
    "plt.title('Bank Account Balance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"background-color: #3933FF; border: 0px; -moz-border-radius: 10px; -webkit-border-radius: 10px;\">\n",
    "<h2 style=\"color: white\">\n",
    "Connecting a Generative AI Platform\n",
    "</h2><br>\n",
    "</div>\n",
    "\n",
    "> #### We connect a Generative AI like OpenAI through LanghChain \n",
    "> #### We use a predefined Agent that execute python commands from natural language \n",
    "> #### This will allow us to explore data easily\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "from langchain.llms import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"OpenAI API key not found. Please set it in your environment variables.\")\n",
    "openai.api_key = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_pandas_dataframe_agent(\n",
    "    ChatOpenAI(temperature=0.5, model=\"gpt-4-1106-preview\"),\n",
    "    df,\n",
    "    verbose=True,\n",
    "    agent_type=AgentType.OPENAI_FUNCTIONS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(\"what is this dataframe and for what can be used?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(\"can you run a Benfords test?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_journalEntry = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>ðŸ’¡ Example:</b> Now with <strong>more</strong> data sets, a journal entry and a trial balance.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = '/Users/andi/Desktop/CPD/Balanta de verificare 29112023 1653.xls'\n",
    "\n",
    "df_trialBalance = pd.read_excel(file_path)\n",
    "\n",
    "df_trialBalance.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trialBalance = pd.read_excel(file_path, header=9)\n",
    "\n",
    "df_trialBalance.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trialBalance.drop(columns=['Unnamed: 2', 'Unnamed: 6'], inplace=True)\n",
    "df_trialBalance.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trialBalance.rename(columns=\n",
    "                       {'Unnamed: 0': 'account', \n",
    "                        'Unnamed: 1': 'Description', \n",
    "                        'Debitoare': 'Opening Debit', \n",
    "                        'Creditoare': 'Opening Credit', \n",
    "                        'Debitoare.1': 'Transaction Debit', \n",
    "                        'Creditoare.1': 'Transaction Credit', \n",
    "                        'Debitoare.2': 'Total Transactions Debit', \n",
    "                        'Creditoare.2': 'Total Transactions Credit', \n",
    "                        'Debitoare.3': 'Closing Debit', \n",
    "                        'Creditoare.3': 'Closing Credit'\n",
    "                        }, \n",
    "                       inplace=True)\n",
    "df_trialBalance.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trialBalance.dropna(subset=['account'], inplace=True)\n",
    "df_trialBalance.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_pandas_dataframe_agent(\n",
    "    ChatOpenAI(temperature=0.5, model=\"gpt-4-1106-preview\"),\n",
    "    [df_trialBalance, df_journalEntry],\n",
    "    verbose=True,\n",
    "    agent_type=AgentType.OPENAI_FUNCTIONS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(\"what informations are in data frames? And how they ralate to eachother\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(\"can you reconcile the information between the two data frames to see if are in agreement?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"background-color: #3933FF; border: 0px; -moz-border-radius: 10px; -webkit-border-radius: 10px;\">\n",
    "<h2 style=\"color: white\">\n",
    "Our Knwoledge Base First\n",
    "</h2><br>\n",
    "</div>\n",
    "\n",
    "> #### We bring to our generative model more knowledge\n",
    "> #### Wetransform that knowledge in to vectors so the model ca access it\n",
    "> #### We use this first knwoledge before going forward to the WWW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: ce este auditul\n",
      "Solution: {'query': 'ce este auditul', 'result': 'Auditul este un proces sistematic, independent È™i documentat prin care se obÈ›ine proba de audit È™i se evalueazÄƒ Ã®n mod obiectiv pentru a determina mÄƒsura Ã®n care criteriile de audit sunt Ã®ndeplinite. Auditul este adesea asociat cu examinarea situaÈ›iilor financiare ale unei entitÄƒÈ›i (cum ar fi o companie, un guvern, o organizaÈ›ie non-profit etc.) pentru a asigura cÄƒ Ã®nregistrÄƒrile sunt un reflex fidel al tranzacÈ›iilor pe care le pretind a reprezenta.\\n\\nÃŽn contextul tehnic al documentului prezentat, auditul pare sÄƒ se refere la auditul financiar, care este procesul prin care un auditor independent examineazÄƒ informaÈ›iile financiare ale unei entitÄƒÈ›i È™i emite o opinie cu privire la acurateÈ›ea È™i corectitudinea acestora. EÈ™antionarea Ã®n audit este o tehnicÄƒ folositÄƒ Ã®n acest proces pentru a testa un subset de tranzacÈ›ii sau Ã®nregistrÄƒri contabile pentru a trage concluzii despre Ã®ntreaga populaÈ›ie.\\n\\nISA (Standardele InternaÈ›ionale de Audit) sunt standarde profesionale pentru efectuarea auditului financiar. Documentul menÈ›ioneazÄƒ mai multe ISA-uri, inclusiv ISA 530 care se referÄƒ la eÈ™antionarea Ã®n audit, ISA 230 care se ocupÄƒ de documentaÈ›ia de audit, È™i ISA 560 care se referÄƒ la evenimente ulterioare care pot afecta situaÈ›iile financiare.\\n\\nÃŽn cazul Ã®n care sunt identificate inconsecvenÈ›e Ã®n probele de audit sau sunt Ã®ndoieli cu privire la credibilitatea acestora, ISA 230 prevede cÄƒ auditorul trebuie sÄƒ documenteze aceste inconsecvenÈ›e È™i sÄƒ analizeze cum afecteazÄƒ concluzia auditului. Acest lucru poate implica obÈ›inerea de probe suplimentare sau reconsiderarea evaluÄƒrii riscului de audit pentru aspectele relevante.', 'source_documents': [Document(page_content='EÈ™antionarea Ã®n audit\\nA57. EÈ™antionarea Ã®n audit are scopul de a permite formularea de concluzii cu pri-\\nvire la o Ã®ntreagÄƒ populaÈ›ie pe baza testÄƒrii unui eÈ™antion selectat din cadrul \\nacesteia. EÈ™antionarea Ã®n audit este discutatÄƒ Ã®n ISA 530.97\\nInconsecvenÈ›a probelor de audit sau Ã®ndoieli cu privire la credibilitatea acestora \\n(A se vedea punctul 11)  \\nA58. ObÈ›inerea probelor de audit din surse diferite sau de naturÄƒ diferitÄƒ poate indica \\nfaptul cÄƒ un element individual din probele de audit nu este credibil, cum ar \\nfi atunci cÃ¢nd o probÄƒ de audit obÈ›inutÄƒ dintr-o sursÄƒ este inconsecventÄƒ cu \\ncea obÈ›inutÄƒ din altÄƒ sursÄƒ. AceastÄƒ situaÈ›ie poate apÄƒrea, de exemplu, atunci \\ncÃ¢nd rÄƒspunsurile obÈ›inute din intervievarea conducerii, a auditorilor interni \\nÈ™i a altor pÄƒrÈ›i sunt inconsecvente sau atunci cÃ¢nd rÄƒspunsurile obÈ›inute din \\nintervievarea persoanelor responsabile cu guvernanÈ›a efectuatÄƒ Ã®n vederea \\ncoroborÄƒrii rÄƒspunsurilor obÈ›inute din intervievarea conducerii sunt incon-\\nsec vente cu rÄƒspunsul conducerii. ISA 230 include o dispoziÈ›ie specificÄƒ pri-\\nvind documentarea Ã®n cazul Ã®n care auditorul a identificat informaÈ›ii care sunt \\ninconsecvente cu concluzia finalÄƒ a auditorului cu privire la un aspect sem ni-\\nficativ.98\\n97 ISA 530, EÈ™antionarea Ã®n audit \\n98 ISA 230, DocumentaÈ›ia de audit , punctul 11', metadata={'page': 1187, 'source': './Manualul-ISA-Vol-I-RO.pdf'}), Document(page_content='por tului auditorului, revizuirea de cÄƒtre auditor a evenimentelor din aceastÄƒ \\nperioadÄƒ ar putea constitui un rÄƒspuns eficace pentru estimÄƒrile contabile, \\naltele decÃ¢t estimÄƒrile contabile la valoarea justÄƒ. Acesta ar putea fi cazul, \\n16 ISA 560, Evenimente ulterioare\\n17 ISA 560, punctul 6\\n18 ISA 560, punctul 8', metadata={'page': 533, 'source': './Manualul-ISA-Vol-I-RO.pdf'}), Document(page_content='de audit, pentru a reflecta schimbarea cadrului, deoarece termenele acceptate \\nanterior nu vor mai fi corecte.\\n10 ISA 800 (revizuit), Considerente speciale â€“ audituri ale situaÅ£iilor financiare Ã®ntocmite Ã®n conformitate \\ncu cadre de raportare cu scop special , punctul 8', metadata={'page': 124, 'source': './Manualul-ISA-Vol-I-RO.pdf'}), Document(page_content='se folosesc aceleaÈ™i tipuri de proceduri de audit. Astfel, auditorul poate decide \\ncÄƒ este eficient sÄƒ testeze eficacitatea cu care funcÈ›ioneazÄƒ controalele con co-\\nmitent cu evaluarea proiectÄƒrii lor È™i cu stabilirea mÄƒsurii Ã®n care acestea au \\nfost implementate.', metadata={'page': 373, 'source': './Manualul-ISA-Vol-I-RO.pdf'})]}\n",
      "Type: in_training\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Solution(BaseModel):\n",
    "    error: str\n",
    "    solution: str\n",
    "    type: str \n",
    "\n",
    "class DocumentProcessor:\n",
    "    def __init__(self, pdf_path):\n",
    "        self.pdf_path = pdf_path\n",
    "\n",
    "    def process(self):\n",
    "        loader = PyPDFLoader(self.pdf_path)\n",
    "        docs = loader.load()\n",
    "        splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=150)\n",
    "        return splitter.split_documents(docs)\n",
    "\n",
    "class VectorStoreCreator:\n",
    "    def __init__(self, persist_directory):\n",
    "        self.persist_directory = persist_directory\n",
    "        self.embedding = OpenAIEmbeddings()\n",
    "\n",
    "    def create(self, document_splits):\n",
    "        return Chroma.from_documents(documents=document_splits, embedding=self.embedding, persist_directory=self.persist_directory)\n",
    "\n",
    "class QAChainSetup:\n",
    "    @staticmethod\n",
    "    def setup(vector_store):\n",
    "        chat_model = ChatOpenAI(model_name=\"gpt-4-1106-preview\", temperature=0.5)\n",
    "        prompt_template = PromptTemplate(\n",
    "            input_variables=[\"context\", \"question\"],\n",
    "            template=\"\"\"You are analyzing a technical document to find solutions for specific errors.\n",
    "                        {context}\n",
    "                        Error Query: {question}\n",
    "                        Possible Solution:\"\"\"\n",
    "        )\n",
    "        return RetrievalQA.from_chain_type(\n",
    "            chat_model,\n",
    "            retriever=vector_store.as_retriever(),\n",
    "            return_source_documents=True,\n",
    "            chain_type_kwargs={\"prompt\": prompt_template}\n",
    "        )\n",
    "\n",
    "class ErrorAnalyzer:\n",
    "    def __init__(self, qa_chain, chat_model):\n",
    "        self.qa_chain = qa_chain\n",
    "        self.chat_model = chat_model\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_data(data):\n",
    "        return data.strip() if isinstance(data, str) else data\n",
    "\n",
    "    def analyze_errors(self, error_data):\n",
    "        return [self.process_error(error) for error in error_data]\n",
    "\n",
    "    def process_error(self, error):\n",
    "        response = self.qa_chain({\"query\": error})\n",
    "        text_content = response.result if hasattr(response, 'result') else str(response)\n",
    "        clean_response = self.clean_data(text_content)\n",
    "        \n",
    "        if \"no relevant information found\" in clean_response or clean_response == \"\":\n",
    "            return self.handle_extended_solution(error), \"extended\"\n",
    "        else:\n",
    "            return (error, clean_response), \"in_training\"\n",
    "\n",
    "    def handle_extended_solution(self, error):\n",
    "        gpt_response = self.chat_model({\"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": error}]})\n",
    "        clean_gpt_response = self.clean_data(gpt_response['choices'][0]['message']['content'])\n",
    "        return (error, clean_gpt_response)\n",
    "\n",
    "def main():\n",
    "    # Ask the user to input the error message\n",
    "    error_message = input(\"Please enter the error message: \")\n",
    "\n",
    "    document_processor = DocumentProcessor(pdf_path=\"./Manualul-ISA-Vol-I-RO.pdf\")\n",
    "    document_splits = document_processor.process()\n",
    "\n",
    "    vector_store_creator = VectorStoreCreator(persist_directory='docs/chroma/')\n",
    "    vector_store = vector_store_creator.create(document_splits)\n",
    "\n",
    "    qa_chain = QAChainSetup.setup(vector_store)\n",
    "    chat_model = ChatOpenAI(model_name=\"gpt-4-1106-preview\", temperature=0.5)\n",
    "\n",
    "    error_analyzer = ErrorAnalyzer(qa_chain, chat_model)\n",
    "\n",
    "    # Process the user-inputted error message\n",
    "    solutions = error_analyzer.analyze_errors([error_message])\n",
    "\n",
    "    # Print the solutions\n",
    "    for solution in solutions:\n",
    "        error, response = solution[0]\n",
    "        print(f\"Error: {error}\\nSolution: {response}\\nType: {solution[1]}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
